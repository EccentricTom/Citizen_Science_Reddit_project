{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary packages\n",
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom113473\n"
     ]
    }
   ],
   "source": [
    "#create a reddit login. Since the parameters would should the users' password, a JSON file was used to store sensitive information.\n",
    "with open(\"C:/Users/tom/OneDrive/Documents/Propulsion/Work/Sensitive/reddit_json.json\") as infile: #this needs to be changed to your working directory \n",
    "    credentials = json.load(infile)\n",
    "reddit = praw.Reddit(client_id = credentials[\"client_id\"],\n",
    "                     client_secret = credentials[\"client_secret\"],\n",
    "                     user_agent=credentials[\"user_agent\"],\n",
    "                     username=credentials[\"username\"],\n",
    "                    password=credentials[\"password\"])\n",
    "\n",
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit: whatsthissnake\n",
      "whatsthissnake completed; total 25 posts has been scraped\n"
     ]
    }
   ],
   "source": [
    "#Create the lists we will use for the data frame\n",
    "\n",
    "date_list = []\n",
    "author_list = []\n",
    "id_list = []\n",
    "link_flair_text_list = []\n",
    "title_list = []\n",
    "url_list = []\n",
    "\n",
    "subred = input(\"Subreddit: \")\n",
    "\n",
    "subreddit = reddit.subreddit(subred)\n",
    "top_post = subreddit.top(limit = 25)\n",
    "\n",
    "for sub in top_post:\n",
    "    date_list.append(datetime.datetime.fromtimestamp(sub.created_utc))\n",
    "    author_list.append(sub.author)\n",
    "    id_list.append(sub.id)        \n",
    "    link_flair_text_list.append(sub.link_flair_text)\n",
    "    title_list.append(sub.title)\n",
    "    url_list.append(sub.url)\n",
    "\n",
    "print(subred, 'completed; ', end='')\n",
    "print('total', len(author_list), 'posts has been scraped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that creates useable hyperlinks from the URL\n",
    "\n",
    "def convert(row, col = \"URL\"):\n",
    "    \"\"\"\n",
    "    This function will convert strings into hyperlinks, makes it easier to pull images\n",
    "    \"\"\"\n",
    "    return \"<a href='{}'>{}</a>\".format(row[col], row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe\n",
    "df = pd.DataFrame({'Date': date_list,\n",
    "                   'Title':title_list,\n",
    "                   'Flair':link_flair_text_list,\n",
    "                   'URL':url_list\n",
    "                  }, index = None)\n",
    "df['URL'] = df.apply(convert, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-12 14:03:55</td>\n",
       "      <td>[META] Dekay's brown snakes</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/d6ed4094zg451.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-03 16:11:56</td>\n",
       "      <td>Hello Folks, found this snake during my run. C...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/sin72flh5kw41.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-18 04:07:08</td>\n",
       "      <td>[META] !deadsnake</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/p10sm0tdiht41.png'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06 04:33:36</td>\n",
       "      <td>[META] very meta</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/lnsgs39xv2941.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-05 20:23:36</td>\n",
       "      <td>A different perspective on our favorite regula...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/wzocelnm78f51.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-08-26 01:07:08</td>\n",
       "      <td>[NC] I know that this is a Timber Rattler but ...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://v.redd.it/9es8vz4ic8j51'&gt;5&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-21 21:33:37</td>\n",
       "      <td>This fellow grabbed a rainbow trout this morni...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/ov3evv5ifb651.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-07 01:18:28</td>\n",
       "      <td>This \"copperhead\" my neighbors were preparing ...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.imgur.com/feYrna8.jpg'&gt;7&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-04-11 03:04:46</td>\n",
       "      <td>East Texas. He’s been hanging around for two y...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/as5u32zy83s41.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-06-29 17:53:24</td>\n",
       "      <td>Found this stole away inside my work truck [So...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/2v4ft1bjfv751.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-05-30 19:09:44</td>\n",
       "      <td>Found while mowing my lawn in Northern Michigan</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.imgur.com/bP5mE6t.jpg'&gt;10&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-09-07 06:22:36</td>\n",
       "      <td>Looks really hard to miss but we walked pet-fi...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/u7ennb34knl51.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-07-07 15:09:38</td>\n",
       "      <td>Beautiful Deadly Snake [Western NC]</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/xkr6kynmpf951.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-08-26 16:23:35</td>\n",
       "      <td>Just moved in to a new house and have friends!...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://imgur.com/MlTrnX6'&gt;13&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-09-07 22:18:29</td>\n",
       "      <td>is this a copperhead? oak ridge, tn</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/p1v3uj9nasl51.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-06-04 18:10:30</td>\n",
       "      <td>No ID needed, just wanted to share this handso...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/mjh9e86t3x251.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-08-12 12:57:21</td>\n",
       "      <td>Found in Florida, never seen a snake with a co...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://v.redd.it/3kjhswdryjg51'&gt;16&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-07-01 03:23:57</td>\n",
       "      <td>Timber Rattlesnake? [New Jersey] She was beaut...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/x6ik9v59e5851.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-06-11 00:45:29</td>\n",
       "      <td>Bunches of these friendly dudes in my backyard...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/o3jpw57rv5451.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-04-23 22:07:14</td>\n",
       "      <td>The Western Diamond Back... is back. Wonder if...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/49qe2aarjmu41.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-06-02 01:38:50</td>\n",
       "      <td>What snake is this [santa barbara, ca] ?</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/r8ay1zd2xd251.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-07-23 18:32:55</td>\n",
       "      <td>Came across this unit on the cherry creek trai...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/95u9hh89hmc51.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-07-03 03:44:38</td>\n",
       "      <td>Stevenson, AL Almost stepped on this dude.</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://v.redd.it/u8u4e6enrj851'&gt;22&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-06-05 13:10:17</td>\n",
       "      <td>Saw this rattling little guy on a hike in Nort...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/1v8ozwr5r2351.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-05-11 18:43:57</td>\n",
       "      <td>Found near [Petoskey, Michigan]. What is this?</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href='https://i.redd.it/04k3oh8sz5y41.jpg'&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                                              Title  \\\n",
       "0  2020-06-12 14:03:55                        [META] Dekay's brown snakes   \n",
       "1  2020-05-03 16:11:56  Hello Folks, found this snake during my run. C...   \n",
       "2  2020-04-18 04:07:08                                  [META] !deadsnake   \n",
       "3  2020-01-06 04:33:36                                   [META] very meta   \n",
       "4  2020-08-05 20:23:36  A different perspective on our favorite regula...   \n",
       "5  2020-08-26 01:07:08  [NC] I know that this is a Timber Rattler but ...   \n",
       "6  2020-06-21 21:33:37  This fellow grabbed a rainbow trout this morni...   \n",
       "7  2020-08-07 01:18:28  This \"copperhead\" my neighbors were preparing ...   \n",
       "8  2020-04-11 03:04:46  East Texas. He’s been hanging around for two y...   \n",
       "9  2020-06-29 17:53:24  Found this stole away inside my work truck [So...   \n",
       "10 2020-05-30 19:09:44    Found while mowing my lawn in Northern Michigan   \n",
       "11 2020-09-07 06:22:36  Looks really hard to miss but we walked pet-fi...   \n",
       "12 2020-07-07 15:09:38                Beautiful Deadly Snake [Western NC]   \n",
       "13 2020-08-26 16:23:35  Just moved in to a new house and have friends!...   \n",
       "14 2020-09-07 22:18:29                is this a copperhead? oak ridge, tn   \n",
       "15 2020-06-04 18:10:30  No ID needed, just wanted to share this handso...   \n",
       "16 2020-08-12 12:57:21  Found in Florida, never seen a snake with a co...   \n",
       "17 2020-07-01 03:23:57  Timber Rattlesnake? [New Jersey] She was beaut...   \n",
       "18 2020-06-11 00:45:29  Bunches of these friendly dudes in my backyard...   \n",
       "19 2020-04-23 22:07:14  The Western Diamond Back... is back. Wonder if...   \n",
       "20 2020-06-02 01:38:50           What snake is this [santa barbara, ca] ?   \n",
       "21 2020-07-23 18:32:55  Came across this unit on the cherry creek trai...   \n",
       "22 2020-07-03 03:44:38         Stevenson, AL Almost stepped on this dude.   \n",
       "23 2020-06-05 13:10:17  Saw this rattling little guy on a hike in Nort...   \n",
       "24 2020-05-11 18:43:57     Found near [Petoskey, Michigan]. What is this?   \n",
       "\n",
       "   Flair                                                URL  \n",
       "0   None  <a href='https://i.redd.it/d6ed4094zg451.jpg'>...  \n",
       "1   None  <a href='https://i.redd.it/sin72flh5kw41.jpg'>...  \n",
       "2   None  <a href='https://i.redd.it/p10sm0tdiht41.png'>...  \n",
       "3   None  <a href='https://i.redd.it/lnsgs39xv2941.jpg'>...  \n",
       "4   None  <a href='https://i.redd.it/wzocelnm78f51.jpg'>...  \n",
       "5   None    <a href='https://v.redd.it/9es8vz4ic8j51'>5</a>  \n",
       "6   None  <a href='https://i.redd.it/ov3evv5ifb651.jpg'>...  \n",
       "7   None    <a href='https://i.imgur.com/feYrna8.jpg'>7</a>  \n",
       "8   None  <a href='https://i.redd.it/as5u32zy83s41.jpg'>...  \n",
       "9   None  <a href='https://i.redd.it/2v4ft1bjfv751.jpg'>...  \n",
       "10  None   <a href='https://i.imgur.com/bP5mE6t.jpg'>10</a>  \n",
       "11  None  <a href='https://i.redd.it/u7ennb34knl51.jpg'>...  \n",
       "12  None  <a href='https://i.redd.it/xkr6kynmpf951.jpg'>...  \n",
       "13  None         <a href='https://imgur.com/MlTrnX6'>13</a>  \n",
       "14  None  <a href='https://i.redd.it/p1v3uj9nasl51.jpg'>...  \n",
       "15  None  <a href='https://i.redd.it/mjh9e86t3x251.jpg'>...  \n",
       "16  None   <a href='https://v.redd.it/3kjhswdryjg51'>16</a>  \n",
       "17  None  <a href='https://i.redd.it/x6ik9v59e5851.jpg'>...  \n",
       "18  None  <a href='https://i.redd.it/o3jpw57rv5451.jpg'>...  \n",
       "19  None  <a href='https://i.redd.it/49qe2aarjmu41.jpg'>...  \n",
       "20  None  <a href='https://i.redd.it/r8ay1zd2xd251.jpg'>...  \n",
       "21  None  <a href='https://i.redd.it/95u9hh89hmc51.jpg'>...  \n",
       "22  None   <a href='https://v.redd.it/u8u4e6enrj851'>22</a>  \n",
       "23  None  <a href='https://i.redd.it/1v8ozwr5r2351.jpg'>...  \n",
       "24  None  <a href='https://i.redd.it/04k3oh8sz5y41.jpg'>...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the top comments for each submission, this is where we get the answers\n",
    "comments = defaultdict(list)\n",
    "for blue in id_list:\n",
    "    submission = reddit.submission(str(blue))\n",
    "    for top_level_comment in submission.comments:\n",
    "        comments[submission.title].append(top_level_comment.body)\n",
    "\n",
    "top_comment = list()\n",
    "for x in comments.values():\n",
    "    top_comment.append(x[0])\n",
    "    \n",
    "df[\"Top Comment\"] = top_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Natural Language Processing to pull the location data from the post\n",
    "\n",
    "location_list = []\n",
    "\n",
    "for title in df.Title:\n",
    "    match = re.search(r'(\\(|\\[)([^)]+)(\\)|\\])',title)\n",
    "    if match:\n",
    "        location_list.append(match.group(2))\n",
    "    else:\n",
    "        location_list.append('N/A')\n",
    "\n",
    "df[\"Location\"] = location_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a CSV file to open up in Streamlit\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\tom\\OneDrive\\Documents\\Propulsion\\Work\\group_projects\\reddit-api-scraping\\data\\observation_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
